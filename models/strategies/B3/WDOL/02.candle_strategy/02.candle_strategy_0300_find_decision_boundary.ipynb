{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81bb84ec1de0c1fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Find Decision Boundary for Test DataFrames\n",
    "\n",
    "In the previous notebooks, we have generated both the train and test dataframes, and the XGBoost model.\n",
    "\n",
    "We need to run the model in the test data, in order to check if the generated model will generate successfull operations.\n",
    "\n",
    "This notebook will also get the XGBoost Models text dump and generate python code that will be used in the FastAPI Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff3054-e221-4721-95e9-e667ba5f93a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:57:39.727546Z",
     "start_time": "2024-03-14T19:57:39.724951Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SHAP_ENABLED=False # For this notebook, we won't be using SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71045f6-e555-4c59-b299-8e4967f91890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:57:40.361736Z",
     "start_time": "2024-03-14T19:57:39.728611Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pandas as pd\n",
    "import joblib\n",
    "if SHAP_ENABLED:\n",
    "    import shap\n",
    "from bokeh.resources import INLINE\n",
    "from bokeh.io import output_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the syspath in order to import the regular pyautotrader module.\n",
    "to_append = os.getcwd() + os.sep + '..' + os.sep + '..' + os.sep + '..' + os.sep + '..' + os.sep + '..'\n",
    "print(to_append)\n",
    "sys.path.append(to_append)\n",
    "\n",
    "from pyautotrader.utils.model_export import export_model_python, create_ast_from_xgboost_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73acae-0d89-41c6-8f74-9174c08785ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:57:40.366763Z",
     "start_time": "2024-03-14T19:57:40.364198Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "SHOULD_GENERATE_IMAGES = platform.system() == 'Windows'\n",
    "if \"SHOULD_GENERATE_IMAGES\" in os.environ:\n",
    "    SHOULD_GENERATE_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2e60a-b741-41d0-a476-7ad7583587b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:57:40.437554Z",
     "start_time": "2024-03-14T19:57:40.368055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_notebook(INLINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38058659bfcdaa4f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017587ae-586e-4441-893c-7a3c8a3d3cb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:57:40.441852Z",
     "start_time": "2024-03-14T19:57:40.438980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_OUTPUT_DIR = os.path.join('..','00.data','output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79173a3b-f762-4b19-bb91-dd3366e9a646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"DATA_OUTPUT_DIR\" in os.environ:\n",
    "    DATA_OUTPUT_DIR = os.environ[\"DATA_OUTPUT_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e414ad-f1f2-4b88-9464-0860a3db2325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_found = [x for x in os.listdir(DATA_OUTPUT_DIR) if x.endswith('.pickle')]\n",
    "files_found_tokens=[x.split('.') for x in files_found]\n",
    "\n",
    "models_found = {}\n",
    "\n",
    "for current_model in files_found_tokens:\n",
    "    model_name = '.'.join(current_model[:-2])\n",
    "    filename = os.path.join(DATA_OUTPUT_DIR,'.'.join(current_model))\n",
    "    if not model_name in models_found:\n",
    "        models_found[model_name]= {}          \n",
    "    models_found[model_name][current_model[-2]]=filename\n",
    "\n",
    "print(models_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabf07dab39001f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will need to load the total dataframe, the parameters dataframe and the raw dataframe, alongside the short and long models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a225a-a397-4525-82d9-d13c30828d4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:58:34.971756Z",
     "start_time": "2024-03-14T19:57:40.512261Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_model = list(models_found.keys())[0]\n",
    "current_total_dataset = joblib.load(models_found[first_model]['total'])\n",
    "current_parameters = joblib.load(models_found[first_model]['parameters'])\n",
    "current_raw_dataset = joblib.load(models_found[first_model]['raw'])\n",
    "\n",
    "best_short_booster = joblib.load(models_found[first_model]['xgboostshortmodel'])\n",
    "best_long_booster = joblib.load(models_found[first_model]['xgboostlongmodel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56388c8988778620",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Configure the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b771c6-f653-4ba3-9b30-8b4c0e0bda0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:58:34.977069Z",
     "start_time": "2024-03-14T19:58:34.974264Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CURRENT_EXCHANGE = current_parameters['CURRENT_EXCHANGE']\n",
    "CURRENT_ASSET = current_parameters['CURRENT_ASSET']\n",
    "CURRENT_TIMEFRAME = current_parameters['CURRENT_TIMEFRAME']\n",
    "CURRENT_TARGET = current_parameters['CURRENT_TARGET']\n",
    "CURRENT_STOP = current_parameters['CURRENT_STOP']\n",
    "MAX_TRADE_DURATION = current_parameters['MAX_TRADE_DURATION']\n",
    "DECISION_BOUNDARY = current_parameters['DECISION_BOUNDARY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23181c33fecaacb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Generate the Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1035aa5-783a-4f43-9776-428f40ba42b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:58:42.072576Z",
     "start_time": "2024-03-14T19:58:34.978226Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_current_total_dataset = pd.DataFrame(current_total_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340f3bc-3385-4ca4-9ed3-98a512f1e276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:58:42.089001Z",
     "start_time": "2024-03-14T19:58:42.073684Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_current_total_dataset = df_current_total_dataset[['current_date', 'current_time', 'is_short','is_long'] + current_parameters['CURRENT_X_COLUMNS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf75e0bac82c452",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Some simple functions to run the predictions of the models in all dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e4cc8-88a9-4bc8-9b33-fae3f7fc451b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:31.169317Z",
     "start_time": "2024-03-14T19:58:42.089981Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_short(row):\n",
    "    a = row[current_parameters['CURRENT_X_COLUMNS']].to_numpy().reshape(1,-1)\n",
    "    return best_short_booster.get_booster().inplace_predict(a)[0]\n",
    "\n",
    "def predict_long(row):\n",
    "    a = row[current_parameters['CURRENT_X_COLUMNS']].to_numpy().reshape(1,-1)\n",
    "    return best_long_booster.get_booster().inplace_predict(a)[0]\n",
    "\n",
    "df_current_total_dataset['short_predict'] = df_current_total_dataset.apply( lambda row: predict_short(row), axis=1)\n",
    "df_current_total_dataset['long_predict'] = df_current_total_dataset.apply( lambda row: predict_long(row), axis=1)\n",
    "df_current_total_dataset['short_cost'] = df_current_total_dataset.apply(  lambda row: ((1 if row['short_predict'] >= DECISION_BOUNDARY else 0) - row['is_short'])**2, axis=1)\n",
    "df_current_total_dataset['long_cost'] = df_current_total_dataset.apply(  lambda row: ((1 if row['long_predict'] >= DECISION_BOUNDARY else 0) - row['is_long'])**2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f420954abf220bbd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will now create a excel spreadsheet with the generated predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382dda6e-1455-431e-8822-364f4dd11f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:38.302494Z",
     "start_time": "2024-03-14T19:59:31.170507Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "check_file_name = f\"{CURRENT_EXCHANGE}.{CURRENT_ASSET}.{CURRENT_TIMEFRAME}.{int(CURRENT_TARGET * 100)}.{int(CURRENT_STOP * 100)}.check_model.xlsx\"\n",
    "check_full_file_name = os.path.join(DATA_OUTPUT_DIR,check_file_name)\n",
    "\n",
    "df_check_predict = df_current_total_dataset[['current_date', 'current_time','is_short','is_long', 'short_predict','long_predict', 'short_cost','long_cost']]\n",
    "df_check_predict.to_excel(check_full_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309136ce9f62d3e5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Clear some memory using the garbage collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc167809-e727-4a41-829d-005c11180a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:38.920023Z",
     "start_time": "2024-03-14T19:59:38.303744Z"
    }
   },
   "outputs": [],
   "source": [
    "current_total_dataset = None\n",
    "df_check_predict = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b141c-fa87-42ff-954a-b642805ec17e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:39.524433Z",
     "start_time": "2024-03-14T19:59:38.921178Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_shap_short(row):\n",
    "    x_columns = row[current_parameters['CURRENT_X_COLUMNS']].to_numpy().reshape(1,-1)\n",
    "    explainer = shap.TreeExplainer(best_short_booster)\n",
    "    shap_values = explainer.shap_values(x_columns)\n",
    "    shap_values = shap_values[0]\n",
    "    shap_values_with_desc = []\n",
    "    for current_column in range(len(current_parameters['CURRENT_X_COLUMNS'])):\n",
    "        shap_values_with_desc.append({ 'desc':current_parameters['CURRENT_X_COLUMNS'][current_column], 'value':shap_values[current_column]})\n",
    "\n",
    "    shap_values_with_desc.sort(key=lambda x: x['value'])\n",
    "    return str(shap_values_with_desc)\n",
    "    \n",
    "\n",
    "def predict_shap_long(row):\n",
    "    x_columns = row[current_parameters['CURRENT_X_COLUMNS']].to_numpy().reshape(1,-1)\n",
    "    explainer = shap.TreeExplainer(best_long_booster)\n",
    "    shap_values = explainer.shap_values(x_columns)\n",
    "    shap_values = shap_values[0]\n",
    "    shap_values_with_desc = []\n",
    "    for current_column in range(len(current_parameters['CURRENT_X_COLUMNS'])):\n",
    "        shap_values_with_desc.append({ 'desc':current_parameters['CURRENT_X_COLUMNS'][current_column], 'value':shap_values[current_column]})\n",
    "\n",
    "    shap_values_with_desc.sort(key=lambda x: x['value'])\n",
    "    return str(shap_values_with_desc)\n",
    "\n",
    "    \n",
    "df_current_total_dataset['short_shap'] = df_current_total_dataset.apply( lambda row: predict_shap_short(row) if (row['short_predict'] > 0 and SHAP_ENABLED) else \"\", axis=1)\n",
    "df_current_total_dataset['long_shap'] = df_current_total_dataset.apply( lambda row: predict_shap_long(row) if (row['long_predict'] > 0 and SHAP_ENABLED) else \"\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126247e6d24ac02d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let us show some predictions, just for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef14bd9-f863-4783-acc0-7e48ae128646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:39.531570Z",
     "start_time": "2024-03-14T19:59:39.525502Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_current_total_dataset[df_current_total_dataset['short_predict'] > 0]['short_shap'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb85e4b43bf78b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will create a histogram of all prediction values for all frames using the short model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e075fa-375f-44dc-8530-39cb524cf786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:40.124544Z",
     "start_time": "2024-03-14T19:59:39.532560Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_file_name = os.path.join(f\"{CURRENT_EXCHANGE}.{CURRENT_ASSET}.{CURRENT_TIMEFRAME}.{int(CURRENT_TARGET * 100)}.{int(CURRENT_STOP * 100)}.hist_short.png\")\n",
    "model_full_file_name = os.path.join(DATA_OUTPUT_DIR,model_file_name)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "df_current_total_dataset.hist('short_predict', ax=ax, bins=500)\n",
    "fig.savefig(model_full_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd51a8222f85926",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will create a histogram of all prediction values for all frames using the short model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316bf86-6088-4d60-af22-88fc43584c71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:40.683470Z",
     "start_time": "2024-03-14T19:59:40.125675Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_file_name = os.path.join(f\"{CURRENT_EXCHANGE}.{CURRENT_ASSET}.{CURRENT_TIMEFRAME}.{int(CURRENT_TARGET * 100)}.{int(CURRENT_STOP * 100)}.hist_long.png\")\n",
    "model_full_file_name = os.path.join(DATA_OUTPUT_DIR,model_file_name)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "df_current_total_dataset.hist('long_predict', ax=ax, bins=500)\n",
    "fig.savefig(model_full_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ccca8ee71053fb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We are going now to generate the trades, and we need to create a separate dataframe will all the predicted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc58add-e310-4d9b-9bd0-7d83b1f46a88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:44.232262Z",
     "start_time": "2024-03-14T19:59:40.684615Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_from_df = df_current_total_dataset.to_dict('records')\n",
    "results = {}\n",
    "short_results = []\n",
    "long_results = []\n",
    "\n",
    "for current_result in results_from_df:\n",
    "    results[(current_result['current_date'] * 10000) + current_result['current_time']] = \\\n",
    "    { \n",
    "        'short_predict' : current_result['short_predict'],\n",
    "        'long_predict' : current_result['long_predict'],\n",
    "        'short_shap' : current_result['short_shap'],\n",
    "        'long_shap' : current_result['long_shap'],\n",
    "    }    \n",
    "    short_results.append(current_result['short_predict'])\n",
    "    long_results.append(current_result['long_predict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b00c776b2af2e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "So, now we are going to loop through the dataframe, and checking if a certain candle generated a trade or not, and then checking its final result. Please notice that we might need to add some risk management like the handling of the stops and so on. \n",
    "\n",
    "After a trade is initiated, it will be executed until it reaches its Gain Target or the Stop loss or it has reached MAX_TRADE_DURATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d8999-8bae-43f8-b0fb-dc57e0c43466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:44.287959Z",
     "start_time": "2024-03-14T19:59:44.233605Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "minimum_short_predict = 0\n",
    "minimum_long_predict = 0\n",
    "\n",
    "maximum_short_predict = int(round(max(short_results),0))\n",
    "maximum_long_predict = int(round(max(long_results),0))\n",
    "\n",
    "current_short_predict = 0\n",
    "current_long_predict = 0\n",
    "\n",
    "current_trade = None\n",
    "current_trade_entries = []\n",
    "processed_dates = {}\n",
    "\n",
    "candle_count = 0\n",
    "current_target = current_parameters['CURRENT_TARGET']\n",
    "current_stop = current_parameters['CURRENT_STOP']\n",
    "\n",
    "for current_candle in current_raw_dataset:\n",
    "    if current_trade is not None:\n",
    "        is_short = current_trade['trade_type'] == 'short'\n",
    "        is_long = current_trade['trade_type'] == 'long'\n",
    "        if is_short:\n",
    "            if current_candle['low'] <= current_trade['trade_target']:\n",
    "                current_trade['result'] =  round(current_trade['trade_start'] - current_trade['trade_target'],2)\n",
    "                current_trade['final_close'] = current_trade['trade_target']\n",
    "                current_trade = None\n",
    "                continue\n",
    "            if current_candle['high'] >= current_trade['trade_stop']:\n",
    "                current_trade['result'] =  round(current_trade['trade_start'] - current_trade['trade_stop'],2)\n",
    "                current_trade['final_close'] = current_trade['trade_stop']\n",
    "                current_trade = None\n",
    "                continue                \n",
    "        if is_long:\n",
    "            if current_candle['low'] <= current_trade['trade_stop']:\n",
    "                current_trade['result'] =  round(current_trade['trade_start'] - current_trade['trade_stop'],2)\n",
    "                current_trade['final_close'] = current_trade['trade_stop']\n",
    "                current_trade = None\n",
    "                continue\n",
    "            if current_candle['high'] >= current_trade['trade_target']:\n",
    "                current_trade['result'] =  round(current_trade['trade_target']- current_trade['trade_target'],2)\n",
    "                current_trade['final_close'] = current_trade['trade_target']\n",
    "                current_trade = None\n",
    "                continue                \n",
    "        if candle_count > (current_trade['start_candle'] + MAX_TRADE_DURATION):\n",
    "            if is_long:\n",
    "                current_trade['result'] =  round(current_candle['close'] - current_trade['trade_start'],2)\n",
    "                current_trade['final_close'] = current_candle['close']\n",
    "            if is_short:\n",
    "                current_trade['result'] =  round(current_trade['trade_start'] - current_candle['close'],2)\n",
    "                current_trade['final_close'] = current_candle['close']\n",
    "            current_trade = None\n",
    "            continue\n",
    "\n",
    "        \n",
    "    if current_trade is None and (current_candle['Date'] not in processed_dates):\n",
    "        if current_candle['Date'] > current_parameters['MINIMUM_DATE_TRADE'] and \\\n",
    "           current_candle['Time'] >= current_parameters['MINIMUM_TIME'] and \\\n",
    "           current_candle['Time'] <= current_parameters['MAXIMUM_TIME']:\n",
    "            current_date_time = (current_candle['Date'] * 10000) + current_candle['Time']\n",
    "            is_entry_point = results[current_date_time]['short_predict'] > DECISION_BOUNDARY or results[current_date_time]['long_predict'] > DECISION_BOUNDARY\n",
    "            if is_entry_point:\n",
    "                is_short = results[current_date_time]['short_predict'] > 0 \n",
    "                current_trade = {**current_candle, \n",
    "                                 'trade_type': 'short' if is_short else 'long', \n",
    "                                 'start_candle': candle_count,\n",
    "                                 'trade_start': current_candle['close'],\n",
    "                                 'predicted': results[current_date_time]['short_predict'] if is_short else results[current_date_time]['long_predict'],\n",
    "                                 'shap': results[current_date_time]['short_shap'] if is_short else results[current_date_time]['long_shap']\n",
    "                                }\n",
    "                if is_short:\n",
    "                    current_trade['trade_target'] = current_candle['close'] * (1 - (current_target / 100))\n",
    "                    current_trade['trade_stop'] = current_candle['close'] * (1 + (current_stop / 100))\n",
    "                else:\n",
    "                    current_trade['trade_target'] = current_candle['close'] * (1 + (current_target / 100))\n",
    "                    current_trade['trade_stop'] = current_candle['close'] * (1 - (current_stop / 100))\n",
    "                    \n",
    "                processed_dates[current_candle['Date']] = '1'\n",
    "                current_trade_entries.append(current_trade)\n",
    "                \n",
    "    candle_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c971702c98393e0c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "After we have interated over all the candles in the dataframe, and generated the trades, we can export them to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931ca94-4ee3-4b06-b41f-5cb4fb48fb70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:44.391231Z",
     "start_time": "2024-03-14T19:59:44.289035Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trades = pd.DataFrame(current_trade_entries)\n",
    "raw_trades_file_name = os.path.join(f\"{CURRENT_EXCHANGE}.{CURRENT_ASSET}.{CURRENT_TIMEFRAME}.{int(CURRENT_TARGET * 100)}.{int(CURRENT_STOP * 100)}.trades.xlsx\")\n",
    "raw_trades_full_file_name = os.path.join(DATA_OUTPUT_DIR,raw_trades_file_name)\n",
    "trades.to_excel(raw_trades_full_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deda93a54856078",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we export the XGBoost model from the txt dump into python code for the Short Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4c76d-55cf-447d-a61b-f8da1d8e0a26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:44.417680Z",
     "start_time": "2024-03-14T19:59:44.392392Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_file_name = os.path.join(f\"{CURRENT_EXCHANGE}.{CURRENT_ASSET}.{CURRENT_TIMEFRAME}.{int(CURRENT_TARGET * 100)}.{int(CURRENT_STOP * 100)}.xgboostshortmodel.txt\")\n",
    "model_full_file_name = os.path.join(DATA_OUTPUT_DIR,model_file_name)\n",
    "\n",
    "python_script_name = 'process_short'\n",
    "python_script_name_short = f'{CURRENT_EXCHANGE}_{CURRENT_ASSET}_{CURRENT_TIMEFRAME}_{int(CURRENT_TARGET * 100)}_{int(CURRENT_STOP * 100)}_process_short'\n",
    "python_code_model_full_file_name = os.path.join(DATA_OUTPUT_DIR,python_script_name_short+'.py')\n",
    "\n",
    "ast = create_ast_from_xgboost_dump(model_full_file_name)\n",
    "export_model_python(ast, python_script_name, python_code_model_full_file_name, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74eb0bc738a2fb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we export the XGBoost model from the txt dump into python code for the Short Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b9e95-4fd7-46f5-a366-f3a4efc946a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:44.444265Z",
     "start_time": "2024-03-14T19:59:44.418922Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_file_name = os.path.join(f\"{CURRENT_EXCHANGE}.{CURRENT_ASSET}.{CURRENT_TIMEFRAME}.{int(CURRENT_TARGET * 100)}.{int(CURRENT_STOP * 100)}.xgboostlongmodel.txt\")\n",
    "model_full_file_name = os.path.join(DATA_OUTPUT_DIR,model_file_name)\n",
    "\n",
    "python_script_name = 'process_long'\n",
    "python_script_name_long = f'{CURRENT_EXCHANGE}_{CURRENT_ASSET}_{CURRENT_TIMEFRAME}_{int(CURRENT_TARGET * 100)}_{int(CURRENT_STOP * 100)}_process_long'\n",
    "python_code_model_full_file_name = os.path.join(DATA_OUTPUT_DIR,python_script_name_long+'.py')\n",
    "\n",
    "ast = create_ast_from_xgboost_dump(model_full_file_name)\n",
    "export_model_python(ast, python_script_name, python_code_model_full_file_name, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f74ae7d6316",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We add the output folder to the PYTHONPATH and import the generated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61c13e-1ab5-4ee1-b40d-43b34d4c9d9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T19:59:44.640623Z",
     "start_time": "2024-03-14T19:59:44.445390Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(DATA_OUTPUT_DIR)\n",
    "exec(f'from {python_script_name_short} import process_short')\n",
    "exec(f'from {python_script_name_long} import process_long')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43d102e41ac5d8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We now run the inference process again, but using the python code and check it to see if its the same as the one generated from XGBoost Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308e7f8-3007-4715-bcac-eadde4cc8abd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T20:00:09.142642Z",
     "start_time": "2024-03-14T19:59:44.641868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_from_df = [{ **x, 'short_from_code' : process_short(x), 'long_from_code': process_long(x)} for x in results_from_df]\n",
    "check_results = pd.DataFrame(results_from_df)\n",
    "check_results['short_bias'] = check_results.apply( lambda row: 0 if ((row['short_predict'] - row['short_from_code']) < 0.00001) else 0.00001 , axis=1)\n",
    "check_results['long_bias'] = check_results.apply( lambda row: 0 if ((row['long_predict'] - row['long_from_code']) < 0.00001) else 0.00001 , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7bc02-578e-455b-82ce-50345e4193aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T20:00:09.163461Z",
     "start_time": "2024-03-14T20:00:09.143652Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_results.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
