{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06572e-1d31-4ed8-8cac-9993379ee28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e10e7ab-2903-4a29-9dd4-264e072c6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join('..','00.data','output')\n",
    "\n",
    "files_found = [x for x in os.listdir(data_folder) if x.endswith('.pickle')]\n",
    "files_found_tokens=[x.split('.') for x in files_found]\n",
    "\n",
    "models_found = {}\n",
    "\n",
    "for current_model in files_found_tokens:\n",
    "    model_name = '.'.join(current_model[:-2])\n",
    "    filename = os.path.join('..','00.data','output','.'.join(current_model))\n",
    "    if not model_name in models_found:\n",
    "        models_found[model_name]= {}          \n",
    "    models_found[model_name][current_model[-2]]=filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2970e-b483-495f-bab2-02cde3318901",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = list(models_found.keys())[0]\n",
    "current_train_dataset = joblib.load(models_found[first_model]['train'])\n",
    "current_test_dataset = joblib.load(models_found[first_model]['test'])\n",
    "current_total_dataset = joblib.load(models_found[first_model]['total'])\n",
    "current_parameters = joblib.load(models_found[first_model]['parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8c33f-75e3-4c6a-be7b-b41f2fc4b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current_train_dataset = pd.DataFrame(current_train_dataset)\n",
    "df_current_train_dataset_x = df_current_train_dataset[current_parameters['CURRENT_X_COLUMNS']]\n",
    "df_current_train_dataset_y_short = df_current_train_dataset[current_parameters['CURRENT_Y_COLUMN_SHORT']]\n",
    "df_current_train_dataset_y_long = df_current_train_dataset[current_parameters['CURRENT_Y_COLUMN_LONG']]\n",
    "\n",
    "train_total_count = len(df_current_train_dataset_x)\n",
    "train_short_count = len([x for x in df_current_train_dataset_y_short if x == True])\n",
    "train_long_count = len([x for x in df_current_train_dataset_y_long if x == True])\n",
    "train_long_ratio = (train_total_count - train_long_count) / train_long_count\n",
    "train_short_ratio = (train_total_count - train_short_count) / train_short_count\n",
    "\n",
    "print(f'(train)Short Count:{train_short_count}/{train_total_count} {(train_short_count/train_total_count) * 100:.2f}%')\n",
    "print(f'(train)Long Count:{train_long_count}/{train_total_count}  {(train_long_count/train_total_count) * 100:.2f}%')\n",
    "print(f'(train)Long Ratio:{train_long_ratio:.2f}')\n",
    "print(f'(train)Short Ratio:{train_short_ratio:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b05a80-2468-4553-b246-56143205184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current_test_dataset = pd.DataFrame(current_test_dataset)\n",
    "df_current_test_dataset_x = df_current_test_dataset[current_parameters['CURRENT_X_COLUMNS']]\n",
    "df_current_test_dataset_y_short = df_current_test_dataset[current_parameters['CURRENT_Y_COLUMN_SHORT']]\n",
    "df_current_test_dataset_y_long = df_current_test_dataset[current_parameters['CURRENT_Y_COLUMN_LONG']]\n",
    "\n",
    "test_total_count = len(df_current_test_dataset_x)\n",
    "test_short_count = len([x for x in df_current_test_dataset_y_short if x == True])\n",
    "test_long_count = len([x for x in df_current_test_dataset_y_long if x == True])\n",
    "\n",
    "print(f'(test)Short Count:{test_short_count}/{test_total_count} {(test_short_count/test_total_count) * 100:.2f}%')\n",
    "print(f'(test)Long Count:{test_long_count}/{test_total_count}  {(test_long_count/test_total_count) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febabffc-47fe-4340-8328-7174dc7ea50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current_train_dataset_x_labels=df_current_train_dataset_x.columns.values\n",
    "dataset_matrix_short_train = xgb.DMatrix(data=df_current_train_dataset_x,label=df_current_train_dataset_y_short, feature_names=df_current_train_dataset_x_labels)\n",
    "dataset_matrix_long_train = xgb.DMatrix(data=df_current_train_dataset_x,label=df_current_train_dataset_y_long, feature_names=df_current_train_dataset_x_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceab1c6-7ff3-44b8-848f-b1dbb95557f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current_test_dataset_x_labels=df_current_test_dataset_x.columns.values\n",
    "dataset_matrix_short_test = xgb.DMatrix(data=df_current_test_dataset_x,label=df_current_test_dataset_y_short, feature_names=df_current_test_dataset_x_labels)\n",
    "dataset_matrix_long_test = xgb.DMatrix(data=df_current_test_dataset_x,label=df_current_test_dataset_y_long, feature_names=df_current_test_dataset_x_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d5e9a3-cb7a-4074-baa8-0c56d0933305",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_res = {}\n",
    "param = {}\n",
    "param['eta'] = 0.3\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'auc'\n",
    "param['tree_method'] = 'exact'\n",
    "param['verbosity'] = 0\n",
    "param['max_depth'] = 5\n",
    "\n",
    "best_recall = 0.0\n",
    "best_booster = None\n",
    "best_num_rounds = 0\n",
    "best_accuracy = 0\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "\n",
    "for num_round in [100]:\n",
    "    booster = xgb.train(param, dataset_matrix_short_train, num_round, evals=[], evals_result=gpu_res)\n",
    "    train_y_pred = booster.predict(dataset_matrix_short_train)\n",
    "    train_predictions = np.array([value for value in train_y_pred])\n",
    "    accuracy = accuracy_score(df_current_train_dataset_y_short, train_predictions.round())\n",
    "    precision = precision_score(df_current_train_dataset_y_short, train_predictions.round())\n",
    "    recall = recall_score(df_current_train_dataset_y_short, train_predictions.round())\n",
    "    if recall > best_recall:\n",
    "        best_booster = booster\n",
    "        best_recall = recall\n",
    "        best_num_rounds = num_round\n",
    "        best_accuracy = accuracy\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "        print(f'Train - Numbers of rounds:{best_num_rounds}')\n",
    "        print(\"(Base Train)Accuracy Total:{}\".format(best_accuracy))\n",
    "        print(\"(Base Train)Precision:{}\".format(best_precision))\n",
    "        print(\"(Base Train)Recall:{}\".format(best_recall))\n",
    "        test_y_pred = best_booster.predict(dataset_matrix_short_test)\n",
    "        test_predictions = np.array([value for value in test_y_pred])\n",
    "        accuracy = accuracy_score(df_current_test_dataset_y_short, test_predictions.round())\n",
    "        precision = precision_score(df_current_test_dataset_y_short, test_predictions.round())\n",
    "        recall = recall_score(df_current_test_dataset_y_short, test_predictions.round())\n",
    "        print(\"Test...\")\n",
    "        print(\"(Base Test)Accuracy Total:{}\".format(accuracy))\n",
    "        print(\"(Base Test)Precision:{}\".format(precision))\n",
    "        print(\"(Base Test)Recall:{}\".format(recall))        \n",
    "    if best_recall > 0.8 and True:\n",
    "        break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f74db-5fd1-45cd-8882-06bb547f3c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important = best_booster.get_score(importance_type='weight')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6715490b-6322-4c03-ba3a-fe1463b89d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_ASSET = current_parameters['CURRENT_ASSET']\n",
    "CURRENT_TIMEFRAME = current_parameters['CURRENT_TIMEFRAME']\n",
    "CURRENT_TARGET = current_parameters['CURRENT_TARGET']\n",
    "CURRENT_STOP = current_parameters['CURRENT_STOP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214f38f-059a-4c8f-a61d-02178f4cb129",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df_current_total_dataset = pd.DataFrame(current_total_dataset)\n",
    "\n",
    "def predict_short(row):\n",
    "    a = row[current_parameters['CURRENT_X_COLUMNS']].to_numpy().reshape(1,-1)\n",
    "    return best_booster.inplace_predict(a)[0]\n",
    "\n",
    "total_output_file_name = f\"{CURRENT_ASSET}.{CURRENT_TIMEFRAME}.{int(CURRENT_TARGET * 100)}.{int(CURRENT_STOP * 100)}.xlsx\"\n",
    "total_output_full_file_name = os.path.join('..','00.data','output',total_output_file_name)\n",
    "\n",
    "df_current_total_dataset['short_predict'] = df_current_total_dataset.apply( lambda row: predict_short(row), axis=1)\n",
    "df_current_total_dataset.to_excel(total_output_full_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986d0f3-0560-407a-97dc-f2eff7ef1404",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = os.path.join(f\"{CURRENT_ASSET}.{CURRENT_TIMEFRAME}.{int(CURRENT_TARGET * 100)}.{int(CURRENT_STOP * 100)}.{best_num_rounds}.xgboostmodel.txt\")\n",
    "model_full_file_name = os.path.join('..','00.data','output',model_file_name)\n",
    "\n",
    "booster.dump_model(model_full_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a1e55-01e8-45bb-a124-635ff381d53e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
